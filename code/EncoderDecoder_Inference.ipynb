{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03f32535-be1d-41c8-928d-bf4ba9465165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import fasttext\n",
    "from fasttext import util\n",
    "import shutil\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af65e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.load('/home/sju/HyoJun/Creative_semester_system/words.npy')\n",
    "words = words.tolist()\n",
    "y_data1 = np.load('/home/sju/HyoJun/Creative_semester_system/y_data1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "217ca0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, words, landmarks):\n",
    "        self.words = words\n",
    "        self.landmarks = torch.tensor(landmarks, dtype=torch.float32)\n",
    "        self.first_frame = self.landmarks[:, 0, :, :]  # (N, L, D)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        word = self.words[idx]\n",
    "        first_frame = self.first_frame[idx]   # (L, D)\n",
    "        return word, first_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d6d323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbeddingDecoderModel(nn.Module):\n",
    "    def __init__(self, ft_model_path, hidden_size, num_frames, num_landmarks, dim):\n",
    "        super(WordEmbeddingDecoderModel, self).__init__()\n",
    "        self.num_frames = num_frames\n",
    "        self.num_landmarks = num_landmarks\n",
    "        self.dim = dim\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.ft = fasttext.load_model(ft_model_path)\n",
    "        self.embedding_dim = self.ft.get_dimension()\n",
    "        \n",
    "        self.encoder_proj = nn.Linear(self.embedding_dim, hidden_size)\n",
    "\n",
    "        self.decoder_input_proj = nn.Linear(num_landmarks * dim, hidden_size)\n",
    "\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=hidden_size,\n",
    "            nhead=8,\n",
    "            dim_feedforward=hidden_size//2,\n",
    "            dropout=0.3,\n",
    "            activation='relu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=8)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, num_landmarks * dim)\n",
    "\n",
    "    def encode_text(self, batch_words, device='cuda'):\n",
    "        \n",
    "        batch_embeddings = []\n",
    "        for words in batch_words:\n",
    "            word_embeds = [self.ft.get_word_vector(w) for w in words]\n",
    "            batch_embeddings.append(word_embeds)\n",
    "        \n",
    "        embeddings = torch.tensor(batch_embeddings).to(device)\n",
    "        embeddings = self.encoder_proj(embeddings)\n",
    "        \n",
    "        return embeddings\n",
    "\n",
    "    def forward(self, words: list[str], decoder_input: torch.Tensor, device: torch.device):\n",
    "        \n",
    "        memory = self.encode_text(words, device) # (1, 1, 768)\n",
    "\n",
    "        # Prepare decoder input\n",
    "        decoder_input = decoder_input.to(device) # (1, 204, 137, 2)\n",
    "        \n",
    "        batch_size = decoder_input.size(0)\n",
    "        num_frames = decoder_input.size(1)\n",
    "        \n",
    "        decoder_input_flat = decoder_input.view(batch_size, num_frames, -1)\n",
    "        decoder_input_proj = self.decoder_input_proj(decoder_input_flat)  # (B, T, hidden_size)\n",
    "\n",
    "        # Create autoregressive mask\n",
    "        tgt_mask = torch.triu(torch.ones(num_frames, num_frames), diagonal=1).bool().to(device)\n",
    "\n",
    "        # Decode\n",
    "        decoder_output = self.transformer_decoder(\n",
    "            tgt=decoder_input_proj,\n",
    "            memory=memory,\n",
    "            tgt_mask=tgt_mask\n",
    "        )  # (B, T, hidden_size)\n",
    "\n",
    "        output = self.fc(decoder_output)  # (B, T, L*D)\n",
    "        output = output.view(batch_size, num_frames, self.num_landmarks, self.dim)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3625fb30-f173-4bd8-ba4c-f65f98943d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 768\n",
    "NUM_FRAMES = y_data1.shape[1]\n",
    "NUM_LANDMARKS = y_data1.shape[2]\n",
    "DIM = 2\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 1\n",
    "LR = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33211967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WordEmbeddingDecoderModel(\n",
    "    ft_model_path='/home/sju/HyoJun/Creative_semester_system/cc.ko.300.bin',\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_frames=NUM_FRAMES,\n",
    "    num_landmarks=NUM_LANDMARKS,\n",
    "    dim=DIM\n",
    ").cuda()\n",
    "\n",
    "model.load_state_dict(torch.load(f\"/home/sju/HyoJun/Creative_semester_system/Model/text2sign.pth\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9afea6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['고민']\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "\n",
    "word = words[n]\n",
    "landmark = y_data1[n, ...]\n",
    "\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db01ea4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36674/44574419.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  embeddings = torch.tensor(batch_embeddings).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 204, 137, 2)\n",
      "CPU times: user 9.53 s, sys: 4.31 ms, total: 9.54 s\n",
      "Wall time: 556 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_dataset = TestDataset(word, landmark[None, ...])\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "preds_list = []\n",
    "for batch in test_dataloader:\n",
    "    word, first_frame = batch\n",
    "    word = word\n",
    "    first_frame = first_frame.cuda()\n",
    "    \n",
    "    current_dec_input = first_frame.unsqueeze(1)   #.float()\n",
    "    \n",
    "    for step in range(NUM_FRAMES):  \n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(word, current_dec_input, 'cuda')\n",
    "            last_frame = output[:, -1, :, :]  # (B, L, D)\n",
    "            last_frame_unsq = last_frame.unsqueeze(1)  # (B, 1, L, D)\n",
    "            current_dec_input = torch.cat([current_dec_input, last_frame_unsq], dim=1)\n",
    "\n",
    "    final_pred = current_dec_input[:, 1:, :, :]  # (batch, NUM_FRAMES, L, D)\n",
    "\n",
    "    preds_list.append(final_pred.cpu())\n",
    "\n",
    "preds = torch.cat(preds_list, dim=0).numpy()\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0184f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/sju/HyoJun/Creative_semester_system/scalers.pkl', 'rb') as f:\n",
    "    scalers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "088c20e0-49a2-48d5-8fda-46bfc7acc525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored y_data shape: (1, 204, 137, 2)\n"
     ]
    }
   ],
   "source": [
    "y_data_restored = []\n",
    "\n",
    "for arr_normalized, scaler in zip(preds, scalers):\n",
    "    arr_restored = scaler.inverse_transform(arr_normalized.reshape(-1, arr_normalized.shape[-1])).reshape(arr_normalized.shape)\n",
    "    y_data_restored.append(arr_restored)\n",
    "\n",
    "y_data_restored = np.array(y_data_restored)\n",
    "print(\"Restored y_data shape:\", y_data_restored.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8153015f-b81c-4bc7-b13e-63742321dcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 204, 137, 2)\n"
     ]
    }
   ],
   "source": [
    "preds_inv = y_data_restored\n",
    "print(preds_inv.shape)\n",
    "np.save(f\"/home/sju/HyoJun/Creative_semester_system/preds/sign_preds{n+1}.npy\", preds_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860753dc-7d3d-4551-ac65-123ccdb9c252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082fd775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "p3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
